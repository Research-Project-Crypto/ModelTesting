{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 14:02:34.930536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 14:02:34.958305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-18 14:02:34.958488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# !pip install jupyterplot\n",
    "# !pip install matplotlib\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install pandas\n",
    "# !pip install tensorflow-gpu\n",
    "# !pip install scikit-learn\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0, 1, 2, 3\n",
    "import tensorflow as tf\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.utils import class_weight\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "\n",
    "# from jupyterplot import ProgressPlot\n",
    "# import copy\n",
    "# import time\n",
    "from itertools import count\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_ENABLE_GPU_GARBAGE_COLLECTION\"] = 'false'\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "# if len(physical_devices) > 0:\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DQN(nn.Module):\n",
    "#     def __init__(self, n_actions, feature_size, hidden_size=128):\n",
    "#         super(DQN, self).__init__()\n",
    "#         self.n_actions = n_actions\n",
    "#         self.lstm_1 = nn.LSTM(input_size = feature_size, hidden_size = hidden_size, num_layers = 1, dropout = 0.1)\n",
    "#         self.output_layer = nn.Linear(hidden_size, n_actions)\n",
    "    \n",
    "#     def forward(self, observation, action, hidden = None):\n",
    "#         lstm_input = observation\n",
    "#         if hidden is not None:\n",
    "#             # print('hidden not None')\n",
    "#             # print(observation.shape)\n",
    "#             # print(action.shape)\n",
    "#             lstm_out, hidden_out = self.lstm_1(lstm_input, hidden)\n",
    "#         else:\n",
    "#             # print('hidden None')\n",
    "#             # print(observation.shape)\n",
    "#             # print(action.shape)\n",
    "#             lstm_out, hidden_out = self.lstm_1(lstm_input)\n",
    "#         q_values = self.output_layer(lstm_out)\n",
    "#         return q_values, hidden_out\n",
    "    \n",
    "#     def predict(self, observation, last_action, epsilon, hidden = None):\n",
    "#         q_values, hidden_out = self.forward(observation, last_action, hidden)\n",
    "#         if np.random.uniform() > epsilon:\n",
    "#             action = torch.argmax(q_values[0][0][-1]).item()\n",
    "#         else:\n",
    "#             action = np.random.randint(self.n_actions)\n",
    "#         return action, hidden_out\n",
    "\n",
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, n_actions, feature_size, frame_size, layers = 2, layer_sizes = [128, 128], dropouts = [0.1, 0], batchnormalizations = [0, 0], optimizer='adam'):\n",
    "        super().__init__()\n",
    "        self._n_actions = n_actions\n",
    "        self._feature_size = feature_size\n",
    "        self._frame_size = frame_size\n",
    "\n",
    "        self._model = self.create_model(layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "    \n",
    "    def create_model(self, layers, layer_sizes, dropouts, batchnormalizations, optimizer):\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(layers):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True, input_shape = (self._frame_size, self._feature_size)))\n",
    "            elif i == layers:\n",
    "                model.add(LSTM(units=layer_sizes[i]))\n",
    "            elif i >= len(layer_sizes):\n",
    "                model.add(LSTM(units=layer_sizes[0], return_sequences = True))\n",
    "            else:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True))\n",
    "\n",
    "\n",
    "            if i < len(dropouts) and dropouts[i] > 0:\n",
    "                model.add(Dropout(dropouts[i]))\n",
    "            if i < len(batchnormalizations) and batchnormalizations[i] == 1:\n",
    "                model.add(BatchNormalization()) \n",
    "        \n",
    "        model.add(Dense(units=self._n_actions))\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def forward(self, observation):\n",
    "        q_values = self._model.predict(observation)\n",
    "        # q_values = self._model.make_predict_function(observation)\n",
    "        # print(q_values.all())\n",
    "        return q_values\n",
    "    \n",
    "    def predict(self, observation, epsilon):\n",
    "        q_values = self.forward(observation)\n",
    "        if np.random.uniform() > epsilon:\n",
    "            action = np.argmax(q_values[0][-1], axis=-1)\n",
    "        else:\n",
    "            action = np.random.randint(self._n_actions)\n",
    "        return action\n",
    "    \n",
    "    def fit(self, observations, targets, batch_size):\n",
    "        self._model.fit(observations, targets, batch_size=batch_size)\n",
    "\n",
    "########################## perhapst try this to find a decent optimizer and weight initializer\n",
    "# def create_model(optimizer='adam', dropout_rate = 0.0, kernel_initializer='uniform', neurons = 128, batch_size = 16):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer=kernel_initializer,activation=activation))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(neurons, kernel_initializer=kernel_initializer,activation=activation))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(neurons, kernel_initializer=kernel_initializer,activation=activation))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(y_train.shape[1], kernel_initializer=kernel_initializer, activation='softmax'))\n",
    "\n",
    "#     model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizer,metrics=['accuracy']) \n",
    "#     return model\n",
    "\n",
    "# model = KerasClassifier(build_fn=create_model, batch_size=64, epochs =10)\n",
    "\n",
    "# dropout_rate = [0.0, 0.2, 0.4]\n",
    "# neurons = [128]\n",
    "# init = ['uniform', 'lecun_uniform', 'normal']\n",
    "# optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# epochs = [50] \n",
    "# batch_size = [64] \n",
    "\n",
    "# param_grid = dict(epochs=epochs, batch_size=batch_size,optimizer = optimizer, dropout_rate = dropout_rate,activation = activation, kernel_initializer=init, neurons=neurons)\n",
    "# grid = GridSearchCV(estimator=model, param_grid = param_grid,verbose=3)\n",
    "# grid_result = grid.fit(X_train, y_train) \n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpBuffer():\n",
    "    def __init__(self, max_storage, sample_length):\n",
    "        self.max_storage = max_storage\n",
    "        self.sample_length = sample_length\n",
    "        self.counter = -1\n",
    "        self.filled = -1\n",
    "        self.storage = [0 for i in range(max_storage)]\n",
    "\n",
    "    def write_tuple(self, oarod):\n",
    "        if self.counter < self.max_storage-1:\n",
    "            self.counter +=1\n",
    "        if self.filled < self.max_storage:\n",
    "            self.filled += 1\n",
    "        else:\n",
    "            self.counter = 0\n",
    "        self.storage[self.counter] = oarod\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        #Returns sizes of (batch_size, seq_len, *) depending on action/observation/return/done\n",
    "        seq_len = self.sample_length\n",
    "        last_actions = []\n",
    "        last_observations = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        observations = []\n",
    "        dones = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if self.filled - seq_len < 0 :\n",
    "                raise Exception(\"Reduce seq_len or increase exploration at start.\")\n",
    "            start_idx = np.random.randint(self.filled-seq_len)\n",
    "            #print(self.filled)\n",
    "            #print(start_idx)\n",
    "            last_observation, action, reward, observation, done = zip(*self.storage[start_idx:start_idx+seq_len])\n",
    "            \n",
    "            # print(len(last_observation[0]))\n",
    "            last_observations.append(last_observation)\n",
    "            actions.append(list(action))\n",
    "            rewards.append(list(reward))\n",
    "            observations.append(list(observation))\n",
    "            dones.append(list(done))\n",
    "           \n",
    "        return last_observations, actions, rewards, observations, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions [0,1,2]\n",
    "# 0 = do nothing\n",
    "# 1 = buy\n",
    "# 2 = sell\n",
    "\n",
    "class CryptoEnv:\n",
    "    _actions = [0,1,2]\n",
    "    _frame_pos = 0\n",
    "    _pos = -1\n",
    "    \n",
    "    def __init__(self, filename, frame_size = 128):\n",
    "        self._frame_size = frame_size\n",
    "        \n",
    "        self._filename = filename\n",
    "        self.reset(filename)\n",
    "        \n",
    "        \n",
    "    def __calc_reward(self, sell_pos):\n",
    "        return (sell_pos - self._pos) / sell_pos * 100\n",
    "    \n",
    "    def __init_values(self, df : pd.DataFrame):\n",
    "        mask = [ 'maxprofitclose', 'maxprofitlowhigh' ]\n",
    "        \n",
    "        targets = df[mask].values.tolist()\n",
    "        \n",
    "        mask.append('event_time')\n",
    "        features = df.drop(columns = mask).values.tolist()\n",
    "        \n",
    "        return features, targets\n",
    "\n",
    "    def step(self, action = None):\n",
    "        # print(action)\n",
    "        if action not in self._actions:\n",
    "            raise ValueError(\"Chosen action is not a valid one.\")\n",
    "        \n",
    "        self._frame_pos += 1\n",
    "        \n",
    "        if self._data_length < self._frame_pos + self._frame_size:\n",
    "            return [], 0, True\n",
    "        \n",
    "        # new_state = self._features[self._frame_pos: self._frame_pos + self._frame_size]\n",
    "        new_state = np.reshape(self._features[self._frame_pos: self._frame_pos + self._frame_size], (-1, self._frame_size, self._featurelength))\n",
    "\n",
    "        if self._pos != -1 and action == 2:\n",
    "            reward = self.__calc_reward(self._targets[self._frame_pos + self._frame_size - 1][0])\n",
    "            # print(f\"sell on {self._frame_pos + self._frame_size}: {reward}\")\n",
    "            self._pos = -1\n",
    "            \n",
    "            return new_state, reward, False\n",
    "        \n",
    "        if self._pos == -1 and action == 1:\n",
    "            self._pos = self._targets[self._frame_pos + self._frame_size - 1][0]      \n",
    "            # print(f\"buy on {self._frame_pos + self._frame_size}\")\n",
    "            return new_state, 0, False\n",
    "        \n",
    "        # print(f\"hodl\")\n",
    "        return new_state, 0, False\n",
    "            \n",
    "        \n",
    "    def reset(self, filename = None):\n",
    "        print(\"reset\")\n",
    "        if filename == None:\n",
    "            filename = self._filename\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        self._features, self._targets = self.__init_values(df)\n",
    "        \n",
    "        del(df)\n",
    "        \n",
    "        self._data_length = len(self._features)\n",
    "        self._featurelength = len(self._features[0])\n",
    "        self._frame_pos = random.randint(0, len(self._features)-self._frame_size*2)\n",
    "        self._pos = -1\n",
    "        \n",
    "        return np.reshape(self._features[self._frame_pos: self._frame_pos + self._frame_size], (-1, self._frame_size, self._featurelength))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "feature_size: 7\n",
      "n_actions: 3\n"
     ]
    }
   ],
   "source": [
    "frame_size = 100\n",
    "\n",
    "env = CryptoEnv('./data/AAVEUSDT.csv', frame_size)\n",
    "\n",
    "feature_size = len(env._features[0])\n",
    "n_actions = len(env._actions)\n",
    "\n",
    "M_episodes = 10000\n",
    "replay_buffer_size = 5000\n",
    "# sample_length = 20\n",
    "replay_buffer = ExpBuffer(replay_buffer_size, env._frame_size)\n",
    "batch_size = frame_size\n",
    "eps_start = 0.9\n",
    "eps = eps_start\n",
    "# eps_end = 0.05\n",
    "eps_decay = 0.975\n",
    "# gamma = 0.999\n",
    "# learning_rate = 0.01\n",
    "# blind_prob = 0\n",
    "EXPLORE = 0\n",
    "\n",
    "print(\"feature_size:\", feature_size)\n",
    "print(\"n_actions:\", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_file():\n",
    "    directory = './data/'\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\") or filename.endswith(\".bin\"): \n",
    "            print(os.path.join(directory, filename))\n",
    "            return os.path.join(directory, filename)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new episode 0\n",
      "./data/AAVEUSDT.csv\n",
      "reset\n",
      "0\n",
      "1/1 [==============================] - 11s 11s/step - loss: 5.6000 - accuracy: 0.3461\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 4.4011 - accuracy: 0.4018\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 1.8895 - accuracy: 0.3159\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 1.5883 - accuracy: 0.3396\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 1.3229 - accuracy: 0.3656\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 1.3802 - accuracy: 0.4493\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 1.2040 - accuracy: 0.3844\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 1.1164 - accuracy: 0.4235\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 1.2247 - accuracy: 0.4037\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 1.2006 - accuracy: 0.4032\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 0.9926 - accuracy: 0.4632\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 1.2936 - accuracy: 0.3688\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.9474 - accuracy: 0.4285\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 1.0922 - accuracy: 0.4675\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 1.5297 - accuracy: 0.4627\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.9698 - accuracy: 0.4461\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.8456 - accuracy: 0.4433\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.8294 - accuracy: 0.3722\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.8104 - accuracy: 0.3675\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.7772 - accuracy: 0.3726\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.8236 - accuracy: 0.3576\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 0.8045 - accuracy: 0.4328\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.8402 - accuracy: 0.4392\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.7530 - accuracy: 0.3720\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.7711 - accuracy: 0.3479\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_172446/61239433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mtarget_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                         \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlastbuylocationi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastbuylocationx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pp = ProgressPlot(plot_names = ['Return', 'Exploration'], line_names = ['Value'])\n",
    "dqn = DQN(n_actions, feature_size, env._frame_size, layers = 15, layer_sizes = [512], dropouts = [0.1]*15, batchnormalizations = [1]*15, optimizer='adam')\n",
    "dqn_target = DQN(n_actions, feature_size, env._frame_size, layers = 15, layer_sizes = [512], dropouts = [0.1]*15, batchnormalizations = [1]*15, optimizer='adam')\n",
    "\n",
    "# dqn._model.load_weights('./models/finalweights')\n",
    "dqn_target.set_weights(dqn.get_weights()) \n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0,0],[1,1],[2,2]])\n",
    "\n",
    "for i_episode in range(M_episodes):\n",
    "    print(f\"new episode {i_episode}\")\n",
    "    done = False\n",
    "    hidden = None\n",
    "    last_action = 0\n",
    "    current_return = 0\n",
    "    \n",
    "    last_observation = env.reset(random_file())\n",
    "    \n",
    "    for t in count():\n",
    "    # for t in range(10000):\n",
    "        if t % 10000 == 0:\n",
    "            eps = eps * eps_decay\n",
    "            print(t)\n",
    "\n",
    "        action = dqn.predict(\n",
    "            last_observation,\n",
    "            epsilon = eps\n",
    "        )\n",
    "\n",
    "        observation, reward, done = env.step(action)\n",
    "        # if np.random.rand() < blind_prob:\n",
    "        #     #Induce partial observability\n",
    "        #     observation = np.zeros_like(observation)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        reward = np.sign(reward)\n",
    "        current_return += reward\n",
    "        replay_buffer.write_tuple((last_observation[-1], action, reward, observation[-1], done))\n",
    "        \n",
    "        last_observation = observation\n",
    "\n",
    "        if i_episode >= EXPLORE and t > batch_size:\n",
    "            last_observations, actions, rewards, observations, dones = replay_buffer.sample(batch_size)\n",
    "            rewards = np.reshape(rewards, (len(rewards), batch_size, 1))\n",
    "            predicted_q_values = dqn_target.forward(np.reshape(last_observations[0], (len(last_observations[0]), batch_size, env._featurelength)))\n",
    "\n",
    "            target_values = np.argmax(predicted_q_values, axis = -1)\n",
    "\n",
    "            targets = np.zeros((target_values.shape[0], target_values.shape[1], n_actions))\n",
    "\n",
    "            lastbuylocationi = 0\n",
    "            lastbuylocationx = 0\n",
    "            for i in range(target_values.shape[0]):\n",
    "                for x in range(target_values.shape[1]):                    \n",
    "                    if target_values[i, x] == 2 and rewards[i, x] > 0:\n",
    "                        targets[i, x, 2] = 1\n",
    "                        targets[lastbuylocationi, lastbuylocationx, 1] = 1\n",
    "                    elif target_values[i, x] == 1:\n",
    "                        lastbuylocationi = i\n",
    "                        lastbuylocationx = x\n",
    "                        targets[i, x, target_values[i, x]] = 1\n",
    "                    else:\n",
    "                        targets[i, x, 0] = 1\n",
    "\n",
    "\n",
    "            dqn.fit(np.reshape(last_observations[0], (len(last_observations[0]), batch_size, env._featurelength)), np.reshape(targets, (targets.shape[0], targets.shape[1], n_actions)), batch_size)\n",
    "\n",
    "    # pp.update([[current_return],[eps]])\n",
    "    dqn_target.set_weights(dqn.get_weights())\n",
    "\n",
    "    dqn._model.save_weights(f'./models/model{i_episode}weights')\n",
    "    dqn._model.save(f'models/completemodel{i_episode}')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 02:40:00.183916: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 75). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/completemodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/completemodel/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff8a328040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff8a328f70> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff88775a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff887c7d90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff84dd5150> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff88696ad0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff84e84a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff84d294b0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff84eb8910> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff58700460> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff587a8f10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff58725f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff587c24d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff584fc940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff584fe1d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "dqn._model.save_weights('./models/finalweights')\n",
    "dqn._model.save('models/completemodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
