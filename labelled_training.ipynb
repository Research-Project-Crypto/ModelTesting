{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 21:16:15.780466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:16:15.807043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:16:15.807217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_ENABLE_GPU_GARBAGE_COLLECTION\"] = 'false'\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['timestamp','open','close','high','low','volume','adosc','atr','macd','macd_signal','macd_hist','mfi','upper_band','middle_band','lower_band','rsi','difference_low_high','difference_open_close','target']\n",
    "\n",
    "data_directory = '/home/joren/Coding/cryptodata/Normalized_labelled/'\n",
    "\n",
    "#####################################\n",
    "frame_size = 120\n",
    "layers = 2\n",
    "layer_sizes = [512, 512]\n",
    "dropouts = [0.1, 0.1]\n",
    "batchnormalizations = [0, 0]\n",
    "optimizer = 'adam'\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_info = [\n",
    "    { \"type\": np.uint64, \"count\": 1 },\n",
    "    { \"type\": np.double, \"count\": 17 },\n",
    "    { \"type\": np.int64, \"count\": 1 }\n",
    "]\n",
    "BYTES_EIGHT = 8\n",
    "\n",
    "def read_bin_full_file(file):\n",
    "    f = open(file, 'rb')\n",
    "    b = f.read(-1)\n",
    "\n",
    "    BYTES_TO_READ = 0\n",
    "    for field in field_info:\n",
    "        BYTES_TO_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "    data = []\n",
    "    BYTES_READ = 0\n",
    "    for i in range(0, int(os.path.getsize(file) / BYTES_TO_READ)):\n",
    "        row = []\n",
    "\n",
    "        for idx, field in enumerate(field_info):\n",
    "            row += np.frombuffer(b, dtype=field[\"type\"], count=field[\"count\"], offset=BYTES_READ).tolist()\n",
    "\n",
    "            BYTES_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "        data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_file():\n",
    "    filenames = []\n",
    "    for file in os.listdir(data_directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        filenames.append(filename)\n",
    "        \n",
    "    randomname = filenames[random.randint(0, len(filenames)-1)]\n",
    "    if randomname.endswith(\".bin\"): \n",
    "        print(f\"reading file: {os.path.join(data_directory, randomname)}\")\n",
    "        return os.path.join(data_directory, randomname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, n_actions, feature_size, layers = 2, layer_sizes = [128, 128], dropouts = [0.1, 0], batchnormalizations = [0, 0], optimizer='adam'):\n",
    "        super().__init__()\n",
    "        self._n_actions = n_actions\n",
    "        self._feature_size = feature_size\n",
    "        self._frame_size = frame_size\n",
    "\n",
    "        self._model = self.create_model(layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "    \n",
    "    def create_model(self, layers, layer_sizes, dropouts, batchnormalizations, optimizer):\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(0, layers):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True, input_shape = (self._frame_size, self._feature_size)))\n",
    "            elif i == layers:\n",
    "                model.add(LSTM(units=layer_sizes[i]))\n",
    "            elif i >= len(layer_sizes):\n",
    "                model.add(LSTM(units=layer_sizes[0], return_sequences = True))\n",
    "            else:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True))\n",
    "\n",
    "\n",
    "            if i < len(dropouts) and dropouts[i] > 0:\n",
    "                model.add(Dropout(dropouts[i]))\n",
    "            if i < len(batchnormalizations) and batchnormalizations[i] == 1:\n",
    "                model.add(BatchNormalization()) \n",
    "        \n",
    "        model.add(Dense(units=self._n_actions, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    # def forward(self, observation):\n",
    "    #     q_values = self._model.predict(observation)\n",
    "    #     # q_values = self._model.make_predict_function(observation)\n",
    "    #     # print(q_values.all())\n",
    "    #     return q_values\n",
    "    \n",
    "    # def predict(self, observation, epsilon):\n",
    "    #     q_values = self.forward(observation)\n",
    "    #     if np.random.uniform() > epsilon:\n",
    "    #         action = np.argmax(q_values[0][-1], axis=-1)\n",
    "    #     else:\n",
    "    #         action = np.random.randint(self._n_actions)\n",
    "    #     return action\n",
    "    \n",
    "    # def fit(self, observations, targets, batch_size):\n",
    "    #     self._model.fit(observations, targets, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "def df_split(df):\n",
    "    X = df.drop(columns=['timestamp','target'], axis=0).to_numpy()\n",
    "    Y = df['target'].to_numpy()\n",
    "\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "    y_train_raw = to_categorical(y_train_raw, 3).tolist()\n",
    "    y_test_raw = to_categorical(y_test_raw, 3).tolist()\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(frame_size, X_train_raw.shape[0]): #frame size up to size of array\n",
    "        X_train.append(X_train_raw[i-frame_size:i])\n",
    "        y_train.append(y_train_raw[i-frame_size:i])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(frame_size, X_test_raw.shape[0]): #frame size up to size of array\n",
    "        X_test.append(X_test_raw[i-frame_size:i])\n",
    "        y_test.append(y_test_raw[i-frame_size:i])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/MITHUSDT.bin\n"
     ]
    }
   ],
   "source": [
    "file = random_file()\n",
    "data = read_bin_full_file(file)\n",
    "\n",
    "df = pd.DataFrame(data, columns=column_names) # variable from cell 1\n",
    "\n",
    "del(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = df_split(df)\n",
    "\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26562/2855226511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 21:18:17.862040: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-21 21:18:17.872895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:18:17.873299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:18:17.873429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:18:18.533734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:18:18.533916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:18:18.534050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-21 21:18:18.534149: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-01-21 21:18:18.534436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4652 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-01-21 21:18:18.536255: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "dqn = DQN(y_train.shape[2], X_train.shape[2], layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1154508, 120, 17)\n",
      "(1154508, 120, 3)\n",
      "(120, 17)\n",
      "(120, 3)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_train[0].shape)\n",
    "print(y_train[0].shape)\n",
    "\n",
    "dqn._model.fit(X_train, y_train, epochs = 1, batch_size = 64, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "dqn._model.save_weights(f'./models/model{i_episode}weights')\n",
    "dqn._model.save(f'models/completemodel{i_episode}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
