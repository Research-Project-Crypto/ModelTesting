{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 15:56:37.073041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:37.099578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:37.099733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import keras\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "# from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_ENABLE_GPU_GARBAGE_COLLECTION\"] = 'false'\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['timestamp','open','close','high','low','volume','adosc','atr','macd','macd_signal','macd_hist','mfi','upper_band','middle_band','lower_band','rsi','difference_low_high','difference_open_close','target']\n",
    "\n",
    "data_directory = '/home/joren/Coding/cryptodata/Normalized_labelled/'\n",
    "max_df_length = 50000\n",
    "\n",
    "#####################################\n",
    "frame_size = 240\n",
    "layers = 3\n",
    "layer_sizes = [240]*layers\n",
    "dropouts = [0.5]*layers\n",
    "batchnormalizations = [1]*layers\n",
    "learning_rate = 0.000001\n",
    "optimizer = Adam(learning_rate)\n",
    "\n",
    "# class_weights = {0: 1,\n",
    "#                 1: 50.,\n",
    "#                 2: 50.}\n",
    "\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_info = [\n",
    "    { \"type\": np.uint64, \"count\": 1 },\n",
    "    { \"type\": np.double, \"count\": 17 },\n",
    "    { \"type\": np.int64, \"count\": 1 }\n",
    "]\n",
    "BYTES_EIGHT = 8\n",
    "\n",
    "def read_bin_full_file(file):\n",
    "    f = open(file, 'rb')\n",
    "    b = f.read(-1)\n",
    "\n",
    "    BYTES_TO_READ = 0\n",
    "    for field in field_info:\n",
    "        BYTES_TO_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "    data = []\n",
    "    BYTES_READ = 0\n",
    "    for i in range(0, int(os.path.getsize(file) / BYTES_TO_READ)):\n",
    "        row = []\n",
    "\n",
    "        for idx, field in enumerate(field_info):\n",
    "            row += np.frombuffer(b, dtype=field[\"type\"], count=field[\"count\"], offset=BYTES_READ).tolist()\n",
    "\n",
    "            BYTES_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "        data.append(row)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_file():\n",
    "    filenames = []\n",
    "    for file in os.listdir(data_directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        filenames.append(filename)\n",
    "        \n",
    "    randomname = filenames[random.randint(0, len(filenames)-1)]\n",
    "    if randomname.endswith(\".bin\"): \n",
    "        print(f\"reading file: {os.path.join(data_directory, randomname)}\")\n",
    "        return os.path.join(data_directory, randomname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, n_actions, feature_size, layers = 2, layer_sizes = [128, 128], dropouts = [0.1, 0], batchnormalizations = [0, 0], optimizer='adam'):\n",
    "        super().__init__()\n",
    "        self._n_actions = n_actions\n",
    "        self._feature_size = feature_size\n",
    "        self._frame_size = frame_size\n",
    "\n",
    "        self._model = self.create_model(layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "    \n",
    "    def create_model(self, layers, layer_sizes, dropouts, batchnormalizations, optimizer):\n",
    "        self._optimizer = optimizer\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(0, layers):\n",
    "            if i < len(dropouts) and dropouts[i] > 0:\n",
    "                dropout = dropouts[i]\n",
    "                # model.add(Dropout(dropouts[i]))\n",
    "            if i == 0:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True, input_shape = (self._frame_size, self._feature_size), dropout=dropout))\n",
    "            elif i == layers:\n",
    "                model.add(LSTM(units=layer_sizes[i], dropout=dropout))\n",
    "            elif i >= len(layer_sizes):\n",
    "                model.add(LSTM(units=layer_sizes[0], return_sequences = True, dropout=dropout))\n",
    "            else:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True, dropout=dropout))\n",
    "            \n",
    "            \n",
    "            if i < len(batchnormalizations) and batchnormalizations[i] == 1:\n",
    "                model.add(BatchNormalization()) \n",
    "\n",
    "        model.add(LSTM(units=layer_sizes[0], return_sequences = False, dropout=dropout))\n",
    "        \n",
    "        # model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dense(units=self._n_actions, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def compile(self):\n",
    "        self._model.compile(optimizer=self._optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "        if DEBUG:\n",
    "            print(self._model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "def df_split(df):  \n",
    "    X = df.drop(columns=['timestamp','target'], axis=0).to_numpy()\n",
    "    Y = df['target'].to_numpy()\n",
    "\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, test_size=0.3, shuffle=False)\n",
    "\n",
    "    y_train_raw = to_categorical(y_train_raw, 3).tolist()\n",
    "    y_test_raw = to_categorical(y_test_raw, 3).tolist()\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    # y_train_weights = []\n",
    "    for i in range(frame_size, X_train_raw.shape[0]): #frame size up to size of array\n",
    "        X_train.append(X_train_raw[i-frame_size:i])\n",
    "        # y_train.append(y_train_raw[i-frame_size:i]) # dit wil ik dus graag veranderen naar y_train_raw[i] zodat we enkel op het einde de output hebben\n",
    "        y_train.append(y_train_raw[i])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    # X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(frame_size, X_test_raw.shape[0]): #frame size up to size of array\n",
    "        X_test.append(X_test_raw[i-frame_size:i])\n",
    "        # y_test.append(y_test_raw[i-frame_size:i])\n",
    "        y_test.append(y_test_raw[i])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(f\"\"\"\n",
    "        X_train shape: {X_train.shape}\n",
    "        y_train shape: {y_train.shape}\n",
    "        \"\"\")\n",
    "\n",
    "        print(f\"\"\"\n",
    "        X_train[0] shape: {X_train[0].shape}\n",
    "        y_train[0] shape: {y_train[0].shape}\n",
    "        \"\"\")\n",
    "\n",
    "        print(f\"X_train[0]: {X_train[0]}\")\n",
    "        print(f\"y_train[0]: {y_train[0]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 15:56:44.555343: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-21 15:56:44.556412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:44.556725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:44.556878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:45.010839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:45.011002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:45.011117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-21 15:56:45.011202: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-04-21 15:56:45.011280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3945 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "dqn = DQN(3, 17, layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "# dqn._model.load_weights('./models/model_small_10_V3_weights')\n",
    "dqn.compile()\n",
    "# dqn._model = models.load_model('./models/model_small_10_V3')\n",
    "\n",
    "def test_accuracy(model):\n",
    "    y_pred_raw = np.array(model.predict(X_test))\n",
    "\n",
    "    y_pred = np.argmax(y_pred_raw, axis=-1)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_2 = np.argmax(y_test, axis=-1)\n",
    "    y_test_2 = y_test_2.flatten()\n",
    "\n",
    "    # print(y_pred_raw.shape)\n",
    "    # print(y_test.shape)\n",
    "\n",
    "    # print(y_pred_raw[0])\n",
    "    # print(y_test[0])\n",
    "\n",
    "    # y_pred = y_pred_raw\n",
    "    # y_test_2 = y_test\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Class. report:\n",
    "    {classification_report(y_test_2, y_pred)}\n",
    "    \"\"\")\n",
    "\n",
    "    cf = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "    print(cf)\n",
    "    print(accuracy_score(y_test_2, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/TOMOUSDT.bin\n",
      "34495\n",
      "133\n",
      "132\n",
      "{0: 0.3358940909310528, 1: 87.11779448621554, 2: 87.77777777777777}\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 15:57:06.008551: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 48s 158ms/step - loss: 1.1622 - accuracy: 0.3279\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.1518 - accuracy: 0.3271\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 43s 159ms/step - loss: 1.1427 - accuracy: 0.3323\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 43s 159ms/step - loss: 1.1044 - accuracy: 0.3323\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.1189 - accuracy: 0.3339\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.52     14677\n",
      "           1       0.00      0.40      0.01        42\n",
      "           2       0.00      0.27      0.01        41\n",
      "\n",
      "    accuracy                           0.36     14760\n",
      "   macro avg       0.33      0.34      0.18     14760\n",
      "weighted avg       0.99      0.36      0.52     14760\n",
      "\n",
      "    \n",
      "[[5213 6311 3153]\n",
      " [  17   17    8]\n",
      " [   8   22   11]]\n",
      "35.50813008130081\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/FLOWUSDT.bin\n",
      "34599\n",
      "81\n",
      "80\n",
      "{0: 0.3348844378931954, 1: 143.04526748971193, 2: 144.83333333333334}\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.1396 - accuracy: 0.3392\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.1323 - accuracy: 0.3359\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 43s 159ms/step - loss: 1.0870 - accuracy: 0.3306\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 44s 160ms/step - loss: 1.0703 - accuracy: 0.3329\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0910 - accuracy: 0.3304\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.28      0.43     14681\n",
      "           1       0.00      0.64      0.01        39\n",
      "           2       0.00      0.57      0.01        40\n",
      "\n",
      "    accuracy                           0.28     14760\n",
      "   macro avg       0.33      0.50      0.15     14760\n",
      "weighted avg       0.99      0.28      0.43     14760\n",
      "\n",
      "    \n",
      "[[4044 5754 4883]\n",
      " [   8   25    6]\n",
      " [  10    7   23]]\n",
      "27.723577235772357\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/NEARUSDT.bin\n",
      "34279\n",
      "240\n",
      "241\n",
      "{0: 0.3380106381944242, 1: 48.27777777777778, 2: 48.077455048409405}\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0948 - accuracy: 0.3284\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.1079 - accuracy: 0.3240\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 44s 160ms/step - loss: 1.0755 - accuracy: 0.3285\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 44s 162ms/step - loss: 1.0750 - accuracy: 0.3251\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 44s 162ms/step - loss: 1.0638 - accuracy: 0.3173\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.33      0.50     14613\n",
      "           1       0.01      0.64      0.02        74\n",
      "           2       0.01      0.66      0.02        73\n",
      "\n",
      "    accuracy                           0.33     14760\n",
      "   macro avg       0.34      0.54      0.18     14760\n",
      "weighted avg       0.98      0.33      0.49     14760\n",
      "\n",
      "    \n",
      "[[4834 4464 5315]\n",
      " [  12   47   15]\n",
      " [  19    6   48]]\n",
      "33.39430894308943\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/FLMUSDT.bin\n",
      "34308\n",
      "226\n",
      "226\n",
      "{0: 0.3377249232443356, 1: 51.26843657817109, 2: 51.26843657817109}\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0735 - accuracy: 0.3334\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 44s 160ms/step - loss: 1.0613 - accuracy: 0.3363\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 44s 160ms/step - loss: 1.0725 - accuracy: 0.3368\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 44s 162ms/step - loss: 1.0742 - accuracy: 0.3318\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0638 - accuracy: 0.3367\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.26      0.41     14459\n",
      "           1       0.02      0.49      0.03       150\n",
      "           2       0.02      0.62      0.03       151\n",
      "\n",
      "    accuracy                           0.27     14760\n",
      "   macro avg       0.34      0.46      0.16     14760\n",
      "weighted avg       0.96      0.27      0.41     14760\n",
      "\n",
      "    \n",
      "[[3786 4660 6013]\n",
      " [  34   74   42]\n",
      " [  38   19   94]]\n",
      "26.788617886178862\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/DOGEUSDT.bin\n",
      "34664\n",
      "48\n",
      "48\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/ADAUPUSDT.bin\n",
      "34435\n",
      "162\n",
      "163\n",
      "{0: 0.33647935724311506, 1: 71.52263374485597, 2: 71.0838445807771}\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0275 - accuracy: 0.2589\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0269 - accuracy: 0.2525\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 44s 160ms/step - loss: 1.0214 - accuracy: 0.2475\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 44s 162ms/step - loss: 1.0112 - accuracy: 0.2452\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 44s 162ms/step - loss: 1.0056 - accuracy: 0.2408\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.19      0.32     14628\n",
      "           1       0.01      0.67      0.01        66\n",
      "           2       0.01      0.70      0.02        66\n",
      "\n",
      "    accuracy                           0.19     14760\n",
      "   macro avg       0.34      0.52      0.12     14760\n",
      "weighted avg       0.98      0.19      0.31     14760\n",
      "\n",
      "    \n",
      "[[2762 6046 5820]\n",
      " [  13   44    9]\n",
      " [  11    9   46]]\n",
      "19.32249322493225\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/COMPUSDT.bin\n",
      "34308\n",
      "226\n",
      "226\n",
      "{0: 0.3377249232443356, 1: 51.26843657817109, 2: 51.26843657817109}\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0365 - accuracy: 0.2947\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0501 - accuracy: 0.2907\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - 44s 161ms/step - loss: 1.0391 - accuracy: 0.2910\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - 44s 162ms/step - loss: 1.0285 - accuracy: 0.2861\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - 44s 162ms/step - loss: 1.0242 - accuracy: 0.2873\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.24      0.39     14537\n",
      "           1       0.01      0.67      0.03       111\n",
      "           2       0.01      0.73      0.03       112\n",
      "\n",
      "    accuracy                           0.25     14760\n",
      "   macro avg       0.34      0.55      0.15     14760\n",
      "weighted avg       0.98      0.25      0.38     14760\n",
      "\n",
      "    \n",
      "[[3518 5010 6009]\n",
      " [  13   74   24]\n",
      " [  15   15   82]]\n",
      "24.89159891598916\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/ADAUSDT.bin\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    file = random_file()\n",
    "    data = read_bin_full_file(file)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=column_names) # variable from cell 1\n",
    "    # print(df.tail())\n",
    "    if len(df) < 1000:\n",
    "        continue\n",
    "    df.fillna(0, inplace=True)\n",
    "    # if df.isnull().values.any():\n",
    "    #     print('nan values found')\n",
    "    #     continue\n",
    "\n",
    "    df = df.iloc[120:]\n",
    "\n",
    "    if len(df) > max_df_length:\n",
    "        randstart = random.randint(0, len(df)-max_df_length)\n",
    "        df = df.iloc[randstart:randstart+max_df_length]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = df_split(df)\n",
    "\n",
    "    # print(X_train.shape)\n",
    "    # print(y_train.shape)\n",
    "\n",
    "    y_train_list = np.argmax(y_train, axis=-1)\n",
    "    next_file = False\n",
    "    for i in [0,1,2]:\n",
    "        print(y_train_list.tolist().count(i))\n",
    "        if y_train_list.tolist().count(i) < 50:\n",
    "            next_file = True\n",
    "    if next_file:\n",
    "        continue\n",
    "\n",
    "    class_weights = dict(enumerate(class_weight.compute_class_weight( class_weight='balanced', classes=[0,1,2], y = y_train_list )))\n",
    "    print(class_weights)\n",
    "\n",
    "    # dqn._model.fit(X_train, y_train, epochs = 1, batch_size = 32, callbacks=[tensorboard], class_weight=class_weights)\n",
    "    dqn._model.fit(X_train, y_train, epochs = 5, batch_size = 128, class_weight=class_weights)\n",
    "\n",
    "    # if i > 10:\n",
    "    #     dqn._model.save(f'models/model_small_10_{i}')\n",
    "    test_accuracy(dqn._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'lstm', 'trainable': True, 'batch_input_shape': (None, 320, 17), 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 320, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.3, 'recurrent_dropout': 0.0, 'implementation': 2}\n"
     ]
    }
   ],
   "source": [
    "print(dqn._model.layers[0].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 320, 320)          432640    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 320, 320)         1280      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 320, 320)          820480    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 320, 320)         1280      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 320)               820480    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               41088     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,691,715\n",
      "Trainable params: 8,685,315\n",
      "Non-trainable params: 6,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 17:24:52.139791: I tensorflow/stream_executor/stream.cc:4442] [stream=0x563762950330,impl=0x563762950d50] INTERNAL: stream did not block host until done; was already in an error state\n",
      "2022-02-16 17:24:52.144902: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 55). These functions will not be directly callable after loading.\n",
      "2022-02-16 17:25:12.476506: I tensorflow/stream_executor/stream.cc:4442] [stream=0x563762950330,impl=0x563762950d50] INTERNAL: stream did not block host until done; was already in an error state\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: stream did not block host until done; was already in an error state [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29537/3277010690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# test_accuracy(dqn._model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'models/model_small_10_V3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/model_small_10_V3_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: stream did not block host until done; was already in an error state [Op:Identity]"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "# test_accuracy(dqn._model)\n",
    "print(dqn._model.summary())\n",
    "dqn._model.save(f'models/model_small_3_V1')\n",
    "dqn._model.save_weights('./models/model_small_3_V1_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
