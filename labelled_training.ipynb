{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 15:27:47.295212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:47.326187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:47.326370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import keras\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "# from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_ENABLE_GPU_GARBAGE_COLLECTION\"] = 'false'\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['timestamp','open','close','high','low','volume','adosc','atr','macd','macd_signal','macd_hist','mfi','upper_band','middle_band','lower_band','rsi','difference_low_high','difference_open_close','target']\n",
    "\n",
    "data_directory = '/home/joren/Coding/cryptodata/Normalized_labelled/'\n",
    "max_df_length = 20000\n",
    "\n",
    "#####################################\n",
    "frame_size = 120\n",
    "layers = 10\n",
    "layer_sizes = [512]*layers\n",
    "dropouts = [0.1]*layers\n",
    "batchnormalizations = [1]*layers\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate)\n",
    "\n",
    "# class_weights = {0: 1,\n",
    "#                 1: 50.,\n",
    "#                 2: 50.}\n",
    "\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_info = [\n",
    "    { \"type\": np.uint64, \"count\": 1 },\n",
    "    { \"type\": np.double, \"count\": 17 },\n",
    "    { \"type\": np.int64, \"count\": 1 }\n",
    "]\n",
    "BYTES_EIGHT = 8\n",
    "\n",
    "def read_bin_full_file(file):\n",
    "    f = open(file, 'rb')\n",
    "    b = f.read(-1)\n",
    "\n",
    "    BYTES_TO_READ = 0\n",
    "    for field in field_info:\n",
    "        BYTES_TO_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "    data = []\n",
    "    BYTES_READ = 0\n",
    "    for i in range(0, int(os.path.getsize(file) / BYTES_TO_READ)):\n",
    "        row = []\n",
    "\n",
    "        for idx, field in enumerate(field_info):\n",
    "            row += np.frombuffer(b, dtype=field[\"type\"], count=field[\"count\"], offset=BYTES_READ).tolist()\n",
    "\n",
    "            BYTES_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "        data.append(row)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_file():\n",
    "    filenames = []\n",
    "    for file in os.listdir(data_directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        filenames.append(filename)\n",
    "        \n",
    "    randomname = filenames[random.randint(0, len(filenames)-1)]\n",
    "    if randomname.endswith(\".bin\"): \n",
    "        print(f\"reading file: {os.path.join(data_directory, randomname)}\")\n",
    "        return os.path.join(data_directory, randomname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, n_actions, feature_size, layers = 2, layer_sizes = [128, 128], dropouts = [0.1, 0], batchnormalizations = [0, 0], optimizer='adam'):\n",
    "        super().__init__()\n",
    "        self._n_actions = n_actions\n",
    "        self._feature_size = feature_size\n",
    "        self._frame_size = frame_size\n",
    "\n",
    "        self._model = self.create_model(layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "    \n",
    "    def create_model(self, layers, layer_sizes, dropouts, batchnormalizations, optimizer):\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(0, layers):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True, input_shape = (self._frame_size, self._feature_size)))\n",
    "            elif i == layers:\n",
    "                model.add(LSTM(units=layer_sizes[i]))\n",
    "            elif i >= len(layer_sizes):\n",
    "                model.add(LSTM(units=layer_sizes[0], return_sequences = True))\n",
    "            else:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True))\n",
    "            \n",
    "            if i < len(dropouts) and dropouts[i] > 0:\n",
    "                model.add(Dropout(dropouts[i]))\n",
    "            if i < len(batchnormalizations) and batchnormalizations[i] == 1:\n",
    "                model.add(BatchNormalization()) \n",
    "\n",
    "        model.add(LSTM(units=layer_sizes[0], return_sequences = False))\n",
    "        \n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dense(units=self._n_actions, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "        if DEBUG:\n",
    "            print(model.summary())\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "def df_split(df):  \n",
    "    X = df.drop(columns=['timestamp','target'], axis=0).to_numpy()\n",
    "    Y = df['target'].to_numpy()\n",
    "\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "    y_train_raw = to_categorical(y_train_raw, 3).tolist()\n",
    "    y_test_raw = to_categorical(y_test_raw, 3).tolist()\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    # y_train_weights = []\n",
    "    for i in range(frame_size, X_train_raw.shape[0]): #frame size up to size of array\n",
    "        X_train.append(X_train_raw[i-frame_size:i])\n",
    "        # y_train.append(y_train_raw[i-frame_size:i]) # dit wil ik dus graag veranderen naar y_train_raw[i] zodat we enkel op het einde de output hebben\n",
    "        y_train.append(y_train_raw[i])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    # X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(frame_size, X_test_raw.shape[0]): #frame size up to size of array\n",
    "        X_test.append(X_test_raw[i-frame_size:i])\n",
    "        # y_test.append(y_test_raw[i-frame_size:i])\n",
    "        y_test.append(y_test_raw[i])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(f\"\"\"\n",
    "        X_train shape: {X_train.shape}\n",
    "        y_train shape: {y_train.shape}\n",
    "        \"\"\")\n",
    "\n",
    "        print(f\"\"\"\n",
    "        X_train[0] shape: {X_train[0].shape}\n",
    "        y_train[0] shape: {y_train[0].shape}\n",
    "        \"\"\")\n",
    "\n",
    "        print(f\"X_train[0]: {X_train[0]}\")\n",
    "        print(f\"y_train[0]: {y_train[0]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 15:27:49.201595: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-24 15:27:49.202322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:49.202549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:49.202709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:49.648542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:49.648728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:49.648863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-24 15:27:49.648966: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-01-24 15:27:49.649047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4620 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "dqn = DQN(3, 17, layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "\n",
    "def test_accuracy(model):\n",
    "    y_pred_raw = np.array(model.predict(X_test))\n",
    "\n",
    "    y_pred = np.argmax(y_pred_raw, axis=-1, keepdims=True)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_2 = np.argmax(y_test, axis=-1, keepdims=True)\n",
    "    y_test_2 = y_test_2.flatten()\n",
    "\n",
    "    # print(y_pred_raw.shape)\n",
    "    # print(y_test.shape)\n",
    "\n",
    "    # print(y_pred_raw[0])\n",
    "    # print(y_test[0])\n",
    "\n",
    "    # y_pred = y_pred_raw\n",
    "    # y_test_2 = y_test\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Class. report:\n",
    "    {classification_report(y_test_2, y_pred)}\n",
    "    \"\"\")\n",
    "\n",
    "    cf = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "    print(cf)\n",
    "    print(accuracy_score(y_test_2, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/TFUELUSDT.bin\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 15:28:13.151906: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 61s 684ms/step - loss: 1.3671 - accuracy: 0.3690\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 48s 692ms/step - loss: 1.2141 - accuracy: 0.2883\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 49s 696ms/step - loss: 1.1348 - accuracy: 0.2434\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 49s 699ms/step - loss: 1.1145 - accuracy: 0.4095\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 49s 701ms/step - loss: 1.1156 - accuracy: 0.3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       878\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      1.00      0.01         1\n",
      "\n",
      "    accuracy                           0.00       880\n",
      "   macro avg       0.00      0.33      0.00       880\n",
      "weighted avg       0.00      0.00      0.00       880\n",
      "\n",
      "    \n",
      "[[  0 557 321]\n",
      " [  0   0   1]\n",
      " [  0   0   1]]\n",
      "0.11363636363636363\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/XECUSDT.bin\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 49s 702ms/step - loss: 1.1127 - accuracy: 0.0654\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.1085 - accuracy: 0.4005\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.1347 - accuracy: 0.4127\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.1203 - accuracy: 0.5065\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.1094 - accuracy: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13       864\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.01      1.00      0.02         8\n",
      "\n",
      "    accuracy                           0.08       880\n",
      "   macro avg       0.34      0.36      0.05       880\n",
      "weighted avg       0.98      0.08      0.13       880\n",
      "\n",
      "    \n",
      "[[ 59   0 805]\n",
      " [  0   0   8]\n",
      " [  0   0   8]]\n",
      "7.613636363636364\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/ZENUSDT.bin\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 50s 704ms/step - loss: 1.1122 - accuracy: 0.0516\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 49s 704ms/step - loss: 1.1252 - accuracy: 0.1857\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 49s 705ms/step - loss: 1.2717 - accuracy: 0.3316\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.3978 - accuracy: 0.3054\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.6528 - accuracy: 0.3158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/joren/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       875\n",
      "           1       0.00      1.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.00       880\n",
      "   macro avg       0.00      0.33      0.00       880\n",
      "weighted avg       0.00      0.00      0.00       880\n",
      "\n",
      "    \n",
      "[[  0 875   0]\n",
      " [  0   2   0]\n",
      " [  0   3   0]]\n",
      "0.22727272727272727\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/GNOUSDT.bin\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.1184 - accuracy: 0.0378\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 49s 703ms/step - loss: 1.3340 - accuracy: 0.3310\n",
      "Epoch 3/5\n",
      "58/70 [=======================>......] - ETA: 8s - loss: 1.0915 - accuracy: 0.2085"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    file = random_file()\n",
    "    data = read_bin_full_file(file)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=column_names) # variable from cell 1\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    # if df.isnull().values.any():\n",
    "    #     print('nan values found')\n",
    "    #     continue\n",
    "\n",
    "    df = df.iloc[240:]\n",
    "\n",
    "    if len(df) > max_df_length:\n",
    "        randstart = random.randint(0, len(df)-max_df_length)\n",
    "        df = df.iloc[randstart:randstart+max_df_length]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = df_split(df)\n",
    "\n",
    "    # print(X_train.shape)\n",
    "    # print(y_train.shape)\n",
    "\n",
    "    y_train_list = np.argmax(y_train, axis=-1)\n",
    "    class_weights = dict(enumerate(class_weight.compute_class_weight( class_weight='balanced', classes=[0,1,2], y = y_train_list )))\n",
    "\n",
    "    dqn._model.fit(X_train, y_train, epochs = 5, batch_size = 128, callbacks=[tensorboard], class_weight=class_weights)\n",
    "    test_accuracy(dqn._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "dqn._model.save(f'models/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
