{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "TF-explain requires Opencv. Install Opencv via `pip install opencv-python`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48893/1375016414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_explain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvanilla_gradients\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVanillaGradientsCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KERAS_BACKEND\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tf_explain/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"TF-explain requires Opencv. \"\u001b[0m \u001b[0;34m\"Install Opencv via `pip install opencv-python`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     ) from None\n",
      "\u001b[0;31mImportError\u001b[0m: TF-explain requires Opencv. Install Opencv via `pip install opencv-python`"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import keras\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "# from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_ENABLE_GPU_GARBAGE_COLLECTION\"] = 'false'\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['timestamp','open','close','high','low','volume','adosc','atr','macd','macd_signal','macd_hist','mfi','upper_band','middle_band','lower_band','rsi','difference_low_high','difference_open_close','target']\n",
    "\n",
    "data_directory = '/home/joren/Coding/cryptodata/Normalized_labelled/'\n",
    "max_df_length = 50000\n",
    "\n",
    "#####################################\n",
    "frame_size = 240\n",
    "layers = 2\n",
    "layer_sizes = [256]*layers\n",
    "dropouts = [0.1]*layers\n",
    "batchnormalizations = [1]*layers\n",
    "learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate)\n",
    "\n",
    "# class_weights = {0: 1,\n",
    "#                 1: 50.,\n",
    "#                 2: 50.}\n",
    "\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_info = [\n",
    "    { \"type\": np.uint64, \"count\": 1 },\n",
    "    { \"type\": np.double, \"count\": 17 },\n",
    "    { \"type\": np.int64, \"count\": 1 }\n",
    "]\n",
    "BYTES_EIGHT = 8\n",
    "\n",
    "def read_bin_full_file(file):\n",
    "    f = open(file, 'rb')\n",
    "    b = f.read(-1)\n",
    "\n",
    "    BYTES_TO_READ = 0\n",
    "    for field in field_info:\n",
    "        BYTES_TO_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "    data = []\n",
    "    BYTES_READ = 0\n",
    "    for i in range(0, int(os.path.getsize(file) / BYTES_TO_READ)):\n",
    "        row = []\n",
    "\n",
    "        for idx, field in enumerate(field_info):\n",
    "            row += np.frombuffer(b, dtype=field[\"type\"], count=field[\"count\"], offset=BYTES_READ).tolist()\n",
    "\n",
    "            BYTES_READ += BYTES_EIGHT * field[\"count\"]\n",
    "\n",
    "        data.append(row)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_file():\n",
    "    filenames = []\n",
    "    for file in os.listdir(data_directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        filenames.append(filename)\n",
    "        \n",
    "    randomname = filenames[random.randint(0, len(filenames)-1)]\n",
    "    if randomname.endswith(\".bin\"): \n",
    "        print(f\"reading file: {os.path.join(data_directory, randomname)}\")\n",
    "        return os.path.join(data_directory, randomname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, n_actions, feature_size, layers = 2, layer_sizes = [128, 128], dropouts = [0.1, 0], batchnormalizations = [0, 0], optimizer='adam'):\n",
    "        super().__init__()\n",
    "        self._n_actions = n_actions\n",
    "        self._feature_size = feature_size\n",
    "        self._frame_size = frame_size\n",
    "\n",
    "        self._model = self.create_model(layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "    \n",
    "    def create_model(self, layers, layer_sizes, dropouts, batchnormalizations, optimizer):\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(0, layers):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True, input_shape = (self._frame_size, self._feature_size)))\n",
    "            elif i == layers:\n",
    "                model.add(LSTM(units=layer_sizes[i]))\n",
    "            elif i >= len(layer_sizes):\n",
    "                model.add(LSTM(units=layer_sizes[0], return_sequences = True))\n",
    "            else:\n",
    "                model.add(LSTM(units=layer_sizes[i], return_sequences = True))\n",
    "            \n",
    "            if i < len(dropouts) and dropouts[i] > 0:\n",
    "                model.add(Dropout(dropouts[i]))\n",
    "            if i < len(batchnormalizations) and batchnormalizations[i] == 1:\n",
    "                model.add(BatchNormalization()) \n",
    "\n",
    "        model.add(LSTM(units=layer_sizes[0], return_sequences = False))\n",
    "        \n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        model.add(Dense(units=self._n_actions, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "        if DEBUG:\n",
    "            print(model.summary())\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "def df_split(df):  \n",
    "    X = df.drop(columns=['timestamp','target'], axis=0).to_numpy()\n",
    "    Y = df['target'].to_numpy()\n",
    "\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, test_size=0.25, shuffle=False)\n",
    "\n",
    "    y_train_raw = to_categorical(y_train_raw, 3).tolist()\n",
    "    y_test_raw = to_categorical(y_test_raw, 3).tolist()\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    # y_train_weights = []\n",
    "    for i in range(frame_size, X_train_raw.shape[0]): #frame size up to size of array\n",
    "        X_train.append(X_train_raw[i-frame_size:i])\n",
    "        # y_train.append(y_train_raw[i-frame_size:i]) # dit wil ik dus graag veranderen naar y_train_raw[i] zodat we enkel op het einde de output hebben\n",
    "        y_train.append(y_train_raw[i])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    # X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(frame_size, X_test_raw.shape[0]): #frame size up to size of array\n",
    "        X_test.append(X_test_raw[i-frame_size:i])\n",
    "        # y_test.append(y_test_raw[i-frame_size:i])\n",
    "        y_test.append(y_test_raw[i])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(f\"\"\"\n",
    "        X_train shape: {X_train.shape}\n",
    "        y_train shape: {y_train.shape}\n",
    "        \"\"\")\n",
    "\n",
    "        print(f\"\"\"\n",
    "        X_train[0] shape: {X_train[0].shape}\n",
    "        y_train[0] shape: {y_train[0].shape}\n",
    "        \"\"\")\n",
    "\n",
    "        print(f\"X_train[0]: {X_train[0]}\")\n",
    "        print(f\"y_train[0]: {y_train[0]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 17:27:56.457117: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-29 17:27:56.457875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 17:27:56.458142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 17:27:56.458284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 17:27:56.891166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 17:27:56.891331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 17:27:56.891462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 17:27:56.891559: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-01-29 17:27:56.891639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4630 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "dqn = DQN(3, 17, layers, layer_sizes, dropouts, batchnormalizations, optimizer)\n",
    "# dqn._model = models.load_model('./models/model_small_3')\n",
    "\n",
    "def test_accuracy(model):\n",
    "    y_pred_raw = np.array(model.predict(X_test))\n",
    "\n",
    "    y_pred = np.argmax(y_pred_raw, axis=-1, keepdims=True)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_2 = np.argmax(y_test, axis=-1, keepdims=True)\n",
    "    y_test_2 = y_test_2.flatten()\n",
    "\n",
    "    # print(y_pred_raw.shape)\n",
    "    # print(y_test.shape)\n",
    "\n",
    "    # print(y_pred_raw[0])\n",
    "    # print(y_test[0])\n",
    "\n",
    "    # y_pred = y_pred_raw\n",
    "    # y_test_2 = y_test\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Class. report:\n",
    "    {classification_report(y_test_2, y_pred)}\n",
    "    \"\"\")\n",
    "\n",
    "    cf = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "    print(cf)\n",
    "    print(accuracy_score(y_test_2, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/KSMUSDT.bin\n",
      "36921\n",
      "169\n",
      "170\n",
      "{0: 0.3363939221581214, 1: 73.49112426035504, 2: 73.05882352941177}\n",
      "583/583 [==============================] - 223s 381ms/step - loss: 1.1272 - accuracy: 0.3908\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.58      0.73     12174\n",
      "           1       0.01      0.09      0.01        43\n",
      "           2       0.00      0.40      0.01        43\n",
      "\n",
      "    accuracy                           0.57     12260\n",
      "   macro avg       0.33      0.35      0.25     12260\n",
      "weighted avg       0.99      0.57      0.72     12260\n",
      "\n",
      "    \n",
      "[[7012  580 4582]\n",
      " [  25    4   14]\n",
      " [  24    2   17]]\n",
      "57.36541598694943\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/BZRXUSDT.bin\n",
      "36729\n",
      "265\n",
      "266\n",
      "{0: 0.33815241362411175, 1: 46.867924528301884, 2: 46.69172932330827}\n",
      "583/583 [==============================] - 224s 382ms/step - loss: 1.1415 - accuracy: 0.3389\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.29      0.45     12078\n",
      "           1       0.01      0.37      0.01        91\n",
      "           2       0.01      0.35      0.02        91\n",
      "\n",
      "    accuracy                           0.29     12260\n",
      "   macro avg       0.33      0.34      0.16     12260\n",
      "weighted avg       0.97      0.29      0.45     12260\n",
      "\n",
      "    \n",
      "[[3546 5115 3417]\n",
      " [  26   34   31]\n",
      " [  25   34   32]]\n",
      "29.461663947797717\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/BEARUSDT.bin\n",
      "36922\n",
      "169\n",
      "169\n",
      "{0: 0.3363848112236607, 1: 73.49112426035504, 2: 73.49112426035504}\n",
      "583/583 [==============================] - 224s 384ms/step - loss: 1.1129 - accuracy: 0.3120\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.27      0.42     11869\n",
      "           1       0.01      0.08      0.02       195\n",
      "           2       0.02      0.62      0.03       196\n",
      "\n",
      "    accuracy                           0.27     12260\n",
      "   macro avg       0.33      0.32      0.16     12260\n",
      "weighted avg       0.94      0.27      0.40     12260\n",
      "\n",
      "    \n",
      "[[3148 1162 7559]\n",
      " [  57   16  122]\n",
      " [  52   23  121]]\n",
      "26.794453507340947\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/XRPUPUSDT.bin\n",
      "36265\n",
      "498\n",
      "497\n",
      "{0: 0.3424789742175651, 1: 24.93975903614458, 2: 24.98993963782696}\n",
      "583/583 [==============================] - 224s 383ms/step - loss: 1.1186 - accuracy: 0.3953\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.24      0.39     11807\n",
      "           1       0.02      0.12      0.03       226\n",
      "           2       0.02      0.67      0.04       227\n",
      "\n",
      "    accuracy                           0.25     12260\n",
      "   macro avg       0.33      0.34      0.15     12260\n",
      "weighted avg       0.93      0.25      0.38     12260\n",
      "\n",
      "    \n",
      "[[2877 1783 7147]\n",
      " [  43   28  155]\n",
      " [  48   28  151]]\n",
      "24.92659053833605\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/CELRUSDT.bin\n",
      "37142\n",
      "59\n",
      "59\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/BEAMUSDT.bin\n",
      "36979\n",
      "141\n",
      "140\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/LPTUSDT.bin\n",
      "9757\n",
      "17\n",
      "16\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/TLMUSDT.bin\n",
      "36243\n",
      "508\n",
      "509\n",
      "{0: 0.342686863670226, 1: 24.448818897637796, 2: 24.400785854616895}\n",
      "583/583 [==============================] - 224s 384ms/step - loss: 1.1321 - accuracy: 0.3278\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.49      0.65     11996\n",
      "           1       0.01      0.20      0.02       132\n",
      "           2       0.01      0.28      0.02       132\n",
      "\n",
      "    accuracy                           0.48     12260\n",
      "   macro avg       0.33      0.33      0.23     12260\n",
      "weighted avg       0.96      0.48      0.64     12260\n",
      "\n",
      "    \n",
      "[[5881 2852 3263]\n",
      " [  67   27   38]\n",
      " [  70   25   37]]\n",
      "48.491027732463294\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/XRPUPUSDT.bin\n",
      "36469\n",
      "395\n",
      "396\n",
      "{0: 0.3405632180756259, 1: 31.443037974683545, 2: 31.363636363636363}\n",
      "583/583 [==============================] - 226s 386ms/step - loss: 1.1207 - accuracy: 0.3894\n",
      "\n",
      "    Class. report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.31      0.47     12012\n",
      "           1       0.01      0.60      0.02       124\n",
      "           2       0.01      0.15      0.02       124\n",
      "\n",
      "    accuracy                           0.31     12260\n",
      "   macro avg       0.33      0.35      0.17     12260\n",
      "weighted avg       0.96      0.31      0.46     12260\n",
      "\n",
      "    \n",
      "[[3742 6404 1866]\n",
      " [  36   74   14]\n",
      " [  38   68   18]]\n",
      "31.27243066884176\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/DREPUSDT.bin\n",
      "37062\n",
      "99\n",
      "99\n",
      "reading file: /home/joren/Coding/cryptodata/Normalized_labelled/WTCUSDT.bin\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    file = random_file()\n",
    "    data = read_bin_full_file(file)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=column_names) # variable from cell 1\n",
    "    if len(df) < 5000:\n",
    "        continue\n",
    "    df.fillna(0, inplace=True)\n",
    "    # if df.isnull().values.any():\n",
    "    #     print('nan values found')\n",
    "    #     continue\n",
    "\n",
    "    df = df.iloc[240:]\n",
    "\n",
    "    if len(df) > max_df_length:\n",
    "        randstart = random.randint(0, len(df)-max_df_length)\n",
    "        df = df.iloc[randstart:randstart+max_df_length]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = df_split(df)\n",
    "\n",
    "    # print(X_train.shape)\n",
    "    # print(y_train.shape)\n",
    "\n",
    "    y_train_list = np.argmax(y_train, axis=-1)\n",
    "    next_file = False\n",
    "    for i in [0,1,2]:\n",
    "        print(y_train_list.tolist().count(i))\n",
    "        if y_train_list.tolist().count(i) < 150:\n",
    "            next_file = True\n",
    "    if next_file:\n",
    "        continue\n",
    "\n",
    "    class_weights = dict(enumerate(class_weight.compute_class_weight( class_weight='balanced', classes=[0,1,2], y = y_train_list )))\n",
    "    print(class_weights)\n",
    "\n",
    "    dqn._model.fit(X_train, y_train, epochs = 5, batch_size = 64, callbacks=[tensorboard], class_weight=class_weights)\n",
    "    # if i > 10:\n",
    "    #     dqn._model.save(f'models/model_small_10_{i}')\n",
    "    test_accuracy(dqn._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 240, 128)          74752     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 240, 128)          0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 240, 128)         512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 240, 128)          131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 240, 128)          0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 240, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355,843\n",
      "Trainable params: 355,331\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 17:23:38.780211: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_tiny_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_tiny_3/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe17c55fb80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe17c16aee0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe17c1db670> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "# test_accuracy(dqn._model)\n",
    "print(dqn._model.summary())\n",
    "dqn._model.save(f'models/model_small_15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
